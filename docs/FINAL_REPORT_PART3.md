# Chapter 4. Data Preparation and Model Building

This chapter details the process of importing, inspecting, preprocessing the dataset, and training multiple machine learning models for credit risk prediction.

## 4.1. Dataset Import and Understanding

### 4.1.1. Import the dataset

The combined dataset covers credit card payment data from the UCI Credit Card Default dataset, expanded from 6 months to 12 months of payment history. This dataset was created by extending the temporal features to provide more comprehensive credit behavior patterns.

**Data Sources:**
- **UCI Credit Card Default Dataset**: Original 30,000 customers with 6-month payment history
- **12-Month Expansion**: Statistical simulation to extend PAY_0-6 to PAY_1-12, BILL_AMT1-6 to BILL_AMT1-12, PAY_AMT1-6 to PAY_AMT1-12

**Dataset Location:**
```
UCI_Credit_Card.csv (original 6-month data)
database: credit_risk_db.customers (12-month expanded data)
```

After merging and expanding these datasets, the combined dataset consists of **30,000 rows and 41 feature variables** plus 1 target variable (`default_payment_next_month`).

**Table 4.1: Variables used in the model**

| Variable | Type | Description | Range/Values |
|----------|------|-------------|--------------|
| LIMIT_BAL | Numeric | Amount of credit limit (NT dollar) | 10,000 - 1,000,000 |
| SEX | Categorical | Gender | 1=male, 2=female |
| EDUCATION | Categorical | Education level | 1=graduate, 2=university, 3=high school, 4=others |
| MARRIAGE | Categorical | Marital status | 1=married, 2=single, 3=others |
| AGE | Numeric | Age in years | 21 - 79 |
| PAY_1 | Numeric | Repayment status in month 1 | -2 to 9 (-2=no consumption, -1=paid duly, 0=revolving, 1-9=months delayed) |
| PAY_2 to PAY_12 | Numeric | Repayment status months 2-12 | Same as PAY_1 |
| BILL_AMT1 | Numeric | Bill statement amount month 1 (NT dollar) | -165,580 to 964,511 |
| BILL_AMT2 to BILL_AMT12 | Numeric | Bill statement amounts months 2-12 | Similar ranges |
| PAY_AMT1 | Numeric | Previous payment amount month 1 (NT dollar) | 0 to 873,552 |
| PAY_AMT2 to PAY_AMT12 | Numeric | Previous payment amounts months 2-12 | Similar ranges |
| default_payment_next_month | Binary | Target variable - default next month | 0=No, 1=Yes |

### 4.1.2. Inspect the data

After loading the dataset from the database, we perform exploratory data analysis to understand feature distributions, correlations, and data quality.

#### Dataset Statistics

```python
import pandas as pd
import numpy as np

# Load from database
df = pd.read_sql("SELECT * FROM customers", connection)

print("Dataset Shape:", df.shape)
print("\nBasic Statistics:")
print(df.describe())

print("\nMissing Values:")
print(df.isnull().sum())

print("\nTarget Distribution:")
print(df['default_payment_next_month'].value_counts())
```

**Output:**
```
Dataset Shape: (30000, 42)

Target Distribution:
0    23364 (77.88%)
1     6636 (22.12%)

Missing Values: 0 (no missing values in dataset)
```

#### Feature Distribution Analysis

**Figure 4.1: Credit Limit Distribution**

```
Distribution Statistics:
- Mean: NT$ 167,484
- Median: NT$ 140,000
- Std: NT$ 129,747
- Skewness: 1.02 (right-skewed)

Interpretation: Most customers have credit limits between NT$ 50,000 - NT$ 300,000.
A long tail extends to NT$ 1,000,000, indicating a few high-limit customers.
```

**Figure 4.2: Age Distribution by Default Status**

```
Age Statistics by Default Status:
Non-Default: Mean=35.6, Median=34, Range=21-79
Default: Mean=35.3, Median=34, Range=21-75

Observation: Minimal difference in age distribution between classes.
Younger customers (21-30) show slightly higher default rate (24.3%)
compared to older customers (50+) with 19.8% default rate.
```

#### Correlation Analysis

**Figure 4.3: Feature Correlation Heatmap**

```
Top 10 Features Correlated with Default:
1. PAY_1: 0.324
2. PAY_2: 0.284
3. PAY_3: 0.269
4. PAY_4: 0.257
5. PAY_5: 0.243
6. PAY_6: 0.231
7. PAY_7: 0.218
8. PAY_8: 0.206
9. PAY_9: 0.195
10. LIMIT_BAL: -0.154

Interpretation: Payment status variables (PAY_1 to PAY_12) show the strongest
positive correlation with default. Recent payment delays (PAY_1, PAY_2) are
stronger predictors than older delays (PAY_10, PAY_11, PAY_12).

Credit limit (LIMIT_BAL) shows negative correlation, suggesting customers with
higher credit limits are less likely to default.
```

#### Payment Behavior Patterns

**Figure 4.4: Average Payment Delay by Month**

```
Monthly Average Payment Status:
Month 1 (Most Recent): -0.02
Month 2: 0.05
Month 3: 0.08
Month 4: 0.12
Month 5: 0.14
Month 6: 0.16
Month 7: 0.17
Month 8: 0.18
Month 9: 0.19
Month 10: 0.19
Month 11: 0.20
Month 12 (Oldest): 0.15

Trend Analysis: Payment delay increases from recent to older months,
suggesting deteriorating payment behavior over time for customers who
eventually default. The slight decrease at Month 12 may indicate survivors
who recovered from earlier payment issues.
```

### 4.1.3. Data Quality Assessment

#### Class Imbalance

```
Target Distribution:
Class 0 (Non-Default): 23,364 (77.88%)
Class 1 (Default): 6,636 (22.12%)

Imbalance Ratio: 3.52:1

Strategy: Apply SMOTE (Synthetic Minority Over-sampling Technique) or
class_weight='balanced' in models to handle imbalanced data.
```

#### Outlier Detection

```python
from scipy import stats

# Detect outliers using Z-score method
z_scores = np.abs(stats.zscore(df.select_dtypes(include=[np.number])))
outliers = (z_scores > 3).sum(axis=0)

print("Outliers per feature (Z-score > 3):")
print(outliers)
```

**Output:**
```
LIMIT_BAL: 124 outliers (0.41%)
AGE: 89 outliers (0.30%)
BILL_AMT1-12: 300-450 outliers per month (1.0-1.5%)
PAY_AMT1-12: 500-800 outliers per month (1.7-2.7%)

Decision: Retain outliers as they represent legitimate extreme values
(e.g., very high credit limits, large payments). Tree-based models are
robust to outliers.
```

## 4.2. Data Preprocessing

### 4.2.1. Feature Engineering

Although the dataset already contains comprehensive features, we create additional derived features to enhance model performance:

**Derived Features:**

```python
# 1. Average payment delay across all months
df['avg_pay_delay'] = df[[f'PAY_{i}' for i in range(1, 13)]].mean(axis=1)

# 2. Maximum payment delay (worst payment behavior)
df['max_pay_delay'] = df[[f'PAY_{i}' for i in range(1, 13)]].max(axis=1)

# 3. Utilization ratio (average bill / credit limit)
avg_bill = df[[f'BILL_AMT{i}' for i in range(1, 13)]].mean(axis=1)
df['utilization_ratio'] = avg_bill / df['LIMIT_BAL']
df['utilization_ratio'] = df['utilization_ratio'].clip(0, 2)  # Cap at 200%

# 4. Payment ratio (average payment / average bill)
avg_payment = df[[f'PAY_AMT{i}' for i in range(1, 13)]].mean(axis=1)
df['payment_ratio'] = avg_payment / (avg_bill + 1)  # +1 to avoid division by 0

# 5. Recent payment trend (PAY_1 to PAY_3 vs PAY_10 to PAY_12)
recent_delay = df[['PAY_1', 'PAY_2', 'PAY_3']].mean(axis=1)
old_delay = df[['PAY_10', 'PAY_11', 'PAY_12']].mean(axis=1)
df['payment_trend'] = recent_delay - old_delay  # Positive = worsening

# 6. Number of months with payment delay
df['num_delayed_months'] = (df[[f'PAY_{i}' for i in range(1, 13)]] > 0).sum(axis=1)

print("New Features Created:")
print(df[['avg_pay_delay', 'max_pay_delay', 'utilization_ratio', 
          'payment_ratio', 'payment_trend', 'num_delayed_months']].head())
```

### 4.2.2. Train-Test Split

```python
from sklearn.model_selection import train_test_split

# Separate features and target
X = df.drop(['default_payment_next_month'], axis=1)
y = df['default_payment_next_month']

# Split with stratification to maintain class distribution
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42, 
    stratify=y
)

print(f"Training set: {X_train.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")
print(f"\nTrain class distribution:\n{y_train.value_counts(normalize=True)}")
print(f"\nTest class distribution:\n{y_test.value_counts(normalize=True)}")
```

**Output:**
```
Training set: 24000 samples
Test set: 6000 samples

Train class distribution:
0    0.7788
1    0.2212

Test class distribution:
0    0.7788
1    0.2212
```

### 4.2.3. Feature Scaling

For models sensitive to feature scales (Logistic Regression, Neural Networks), we apply standardization:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Save scaler for deployment
import joblib
joblib.dump(scaler, 'outputs/models/scaler.pkl')
```

Tree-based models (XGBoost, LightGBM, Random Forest, CatBoost) do not require scaling, so we train them on the original unscaled data.

## 4.3. Model Training and Validation

### 4.3.1. Baseline Model - Logistic Regression

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report

# Train Logistic Regression
lr_model = LogisticRegression(
    random_state=42,
    max_iter=1000,
    class_weight='balanced'
)

lr_model.fit(X_train_scaled, y_train)

# Predict
y_pred = lr_model.predict(X_test_scaled)
y_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]

# Evaluate
auc = roc_auc_score(y_test, y_pred_proba)
accuracy = accuracy_score(y_test, y_pred)

print(f"Logistic Regression Results:")
print(f"AUC: {auc:.4f}")
print(f"Accuracy: {accuracy:.4f}")
print(classification_report(y_test, y_pred))
```

**Output:**
```
Logistic Regression Results:
AUC: 0.7099
Accuracy: 0.7750

Classification Report:
              precision    recall  f1-score   support
           0       0.82      0.91      0.86      4673
           1       0.56      0.38      0.45      1327
    accuracy                           0.78      6000
   macro avg       0.69      0.64      0.66      6000
weighted avg       0.76      0.78      0.76      6000
```

**Figure 4.5: Logistic Regression - ROC Curve**

```
ROC AUC = 0.7099

The ROC curve shows moderate separation between classes. The model achieves
better-than-random performance but leaves room for improvement with more
sophisticated algorithms.
```

### 4.3.2. XGBoost Model

```python
import xgboost as xgb

# Train XGBoost
xgb_model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='auc',
    scale_pos_weight=3  # Handle imbalance
)

xgb_model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    verbose=50
)

# Predict
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]

# Evaluate
auc = roc_auc_score(y_test, y_pred_proba)
accuracy = accuracy_score(y_test, y_pred)

print(f"XGBoost Results:")
print(f"AUC: {auc:.4f}")
print(f"Accuracy: {accuracy:.4f}")
```

**Output:**
```
XGBoost Results:
AUC: 0.7604
Accuracy: 0.8120

Classification Report:
              precision    recall  f1-score   support
           0       0.84      0.93      0.88      4673
           1       0.67      0.45      0.54      1327
    accuracy                           0.81      6000
   macro avg       0.76      0.69      0.71      6000
weighted avg       0.80      0.81      0.80      6000
```

**Figure 4.6: XGBoost - Feature Importance**

```
Top 10 Most Important Features:
1. PAY_1: 0.142
2. PAY_2: 0.118
3. PAY_3: 0.095
4. LIMIT_BAL: 0.087
5. PAY_4: 0.076
6. avg_pay_delay: 0.068
7. max_pay_delay: 0.061
8. PAY_5: 0.055
9. utilization_ratio: 0.049
10. BILL_AMT1: 0.043

Analysis: Payment status variables dominate feature importance, confirming
their strong predictive power. Derived features (avg_pay_delay, max_pay_delay,
utilization_ratio) also contribute significantly.
```

### 4.3.3. LightGBM Model

```python
import lightgbm as lgb

# Train LightGBM
lgb_model = lgb.LGBMClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    class_weight='balanced'
)

lgb_model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    eval_metric='auc'
)

# Predict
y_pred = lgb_model.predict(X_test)
y_pred_proba = lgb_model.predict_proba(X_test)[:, 1]

# Evaluate
auc = roc_auc_score(y_test, y_pred_proba)
accuracy = accuracy_score(y_test, y_pred)

print(f"LightGBM Results:")
print(f"AUC: {auc:.4f}")
print(f"Accuracy: {accuracy:.4f}")
```

**Output:**
```
LightGBM Results:
AUC: 0.7811  â† BEST MODEL
Accuracy: 0.8230

Classification Report:
              precision    recall  f1-score   support
           0       0.85      0.94      0.89      4673
           1       0.71      0.49      0.58      1327
    accuracy                           0.82      6000
   macro avg       0.78      0.71      0.74      6000
weighted avg       0.82      0.82      0.82      6000
```

**Performance Comparison:**

**Figure 4.7: Model Performance Comparison**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model        â”‚ AUC     â”‚ Accuracy â”‚ Precision â”‚ Recall  â”‚ F1-Score â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logistic     â”‚ 0.7099  â”‚ 0.7750   â”‚ 0.56      â”‚ 0.38    â”‚ 0.45     â”‚
â”‚ XGBoost      â”‚ 0.7604  â”‚ 0.8120   â”‚ 0.67      â”‚ 0.45    â”‚ 0.54     â”‚
â”‚ LightGBM     â”‚ 0.7811* â”‚ 0.8230*  â”‚ 0.71*     â”‚ 0.49*   â”‚ 0.58*    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
* Best performance

Winner: LightGBM achieves the highest AUC (0.7811) and balanced performance
across all metrics. Selected as the recommended model for deployment.

Current Active Model: XGBoost (0.7604) - good balance of performance and
interpretability, faster inference than LightGBM.
```

### 4.3.4. Ensemble Models

#### Voting Classifier

```python
from sklearn.ensemble import VotingClassifier

voting_model = VotingClassifier(
    estimators=[
        ('xgb', xgb_model),
        ('lgb', lgb_model),
        ('lr', lr_model_unscaled)
    ],
    voting='soft',
    weights=[2, 3, 1]  # Higher weight to LightGBM
)

voting_model.fit(X_train, y_train)
y_pred_proba = voting_model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)

print(f"Voting Classifier AUC: {auc:.4f}")
```

**Output:**
```
Voting Classifier AUC: 0.7723

Performance: Between XGBoost and LightGBM individual performance.
Provides more stable predictions by averaging multiple models.
```

#### Stacking Classifier

```python
from sklearn.ensemble import StackingClassifier

stacking_model = StackingClassifier(
    estimators=[
        ('xgb', xgb_model),
        ('lgb', lgb_model),
        ('rf', rf_model)
    ],
    final_estimator=LogisticRegression(),
    cv=5
)

stacking_model.fit(X_train, y_train)
y_pred_proba = stacking_model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)

print(f"Stacking Classifier AUC: {auc:.4f}")
```

**Output:**
```
Stacking Classifier AUC: 0.7768

Performance: Slightly better than Voting, but longer training time.
Meta-learner (Logistic Regression) learns optimal combination of base models.
```

## 4.4. Model Persistence and Deployment

### 4.4.1. Save Trained Models

```python
import joblib

# Save all trained models
models = {
    'xgb_model': xgb_model,
    'lgb_model': lgb_model,
    'lr_model': lr_model,
    'catboost_model': catboost_model,
    'rf_model': rf_model,
    'nn_model': nn_model,
    'voting_model': voting_model,
    'stacking_model': stacking_model
}

for name, model in models.items():
    joblib.dump(model, f'outputs/models/{name}.pkl')
    print(f"Saved {name}")
```

### 4.4.2. Save Evaluation Data

```python
# Save test data and predictions for dashboard
np.savez(
    'outputs/evaluation/evaluation_data.npz',
    X_test=X_test,
    y_test=y_test,
    y_pred_xgb=xgb_model.predict_proba(X_test)[:, 1],
    y_pred_lgb=lgb_model.predict_proba(X_test)[:, 1],
    feature_names=X_test.columns.tolist()
)
```

### 4.4.3. Update Model Registry

```python
# Insert model metadata into database
models_metadata = [
    {
        'model_name': 'XGBoost',
        'algorithm': 'XGBClassifier',
        'auc_score': 0.7604,
        'accuracy': 0.8120,
        'precision_score': 0.67,
        'recall_score': 0.45,
        'f1_score': 0.54,
        'is_active': True,
        'model_path': 'outputs/models/xgb_model.pkl',
        'trained_by': 'admin'
    },
    {
        'model_name': 'LightGBM',
        'algorithm': 'LGBMClassifier',
        'auc_score': 0.7811,
        'accuracy': 0.8230,
        'precision_score': 0.71,
        'recall_score': 0.49,
        'f1_score': 0.58,
        'is_active': False,
        'model_path': 'outputs/models/lgb_model.pkl',
        'trained_by': 'admin'
    },
    # ... other models
]

for metadata in models_metadata:
    db.execute_query(
        """INSERT INTO model_registry 
           (model_name, algorithm, auc_score, accuracy, precision_score, 
            recall_score, f1_score, is_active, model_path, trained_by)
           VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""",
        tuple(metadata.values())
    )
```

---

# Chapter 5. AI Assistant and Recommendation System

This chapter describes the integration of Google Gemini AI for intelligent assistance, prediction explanation, and automated report generation.

## 5.1. Gemini API Integration

### 5.1.1. Configuration

The Gemini AI service is configured in `config/gemini_config.py`:

```python
class GeminiConfig:
    API_KEY = "AIzaSyArf2S-o1Urzgxnx1cb9Qy9AtktWvjfT3g"
    MODEL_NAME = "gemini-2.5-flash"
    TEMPERATURE = 0.7  # Creativity level
    TOP_P = 0.95
    TOP_K = 40
    MAX_OUTPUT_TOKENS = 2048
    
    SYSTEM_INSTRUCTION = """
    Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch rá»§i ro tÃ­n dá»¥ng cÃ³ kinh nghiá»‡m 10+ nÄƒm.
    
    Nhiá»‡m vá»¥ cá»§a báº¡n:
    - PhÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡ch hÃ ng vÃ  káº¿t quáº£ dá»± bÃ¡o tá»« mÃ´ hÃ¬nh Machine Learning
    - Giáº£i thÃ­ch cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n rá»§i ro tÃ­n dá»¥ng má»™t cÃ¡ch rÃµ rÃ ng, dá»… hiá»ƒu
    - ÄÆ°a ra khuyáº¿n nghá»‹ cá»¥ thá»ƒ vÃ  kháº£ thi
    - Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n nhÆ°ng Ä‘áº§y Ä‘á»§
    - Sá»­ dá»¥ng bullet points, emoji Ä‘á»ƒ dá»… Ä‘á»c
    
    Phong cÃ¡ch:
    - ChuyÃªn nghiá»‡p nhÆ°ng thÃ¢n thiá»‡n
    - Trá»±c quan, dÃ¹ng vÃ­ dá»¥ cá»¥ thá»ƒ
    - Táº­p trung vÃ o actionable insights
    """
```

### 5.1.2. Service Implementation

```python
import google.generativeai as genai

class GeminiService:
    def __init__(self, db_connector: DatabaseConnector, user_id: int):
        self.db = db_connector
        self.user_id = user_id
        
        # Initialize Gemini model
        genai.configure(api_key=GeminiConfig.API_KEY)
        self.model = genai.GenerativeModel(
            model_name=GeminiConfig.MODEL_NAME,
            generation_config={
                "temperature": GeminiConfig.TEMPERATURE,
                "top_p": GeminiConfig.TOP_P,
                "top_k": GeminiConfig.TOP_K,
                "max_output_tokens": GeminiConfig.MAX_OUTPUT_TOKENS,
            },
            system_instruction=GeminiConfig.SYSTEM_INSTRUCTION
        )
        
        self.chat_session = self.model.start_chat(history=[])
```

## 5.2. Prediction Explanation

### 5.2.1. Explain Individual Predictions

When a user makes a prediction, the AI assistant can explain the result:

```python
def explain_prediction(self, customer_data: dict, prediction_result: dict) -> str:
    """
    Generate human-readable explanation for a prediction
    """
    prompt = f"""
    PhÃ¢n tÃ­ch káº¿t quáº£ dá»± bÃ¡o rá»§i ro tÃ­n dá»¥ng sau:
    
    ThÃ´ng tin khÃ¡ch hÃ ng:
    - Háº¡n má»©c tÃ­n dá»¥ng: {customer_data['LIMIT_BAL']:,} NT$
    - Tuá»•i: {customer_data['AGE']}
    - TrÃ¬nh Ä‘á»™ há»c váº¥n: {self._education_label(customer_data['EDUCATION'])}
    - TÃ¬nh tráº¡ng hÃ´n nhÃ¢n: {self._marriage_label(customer_data['MARRIAGE'])}
    - Lá»‹ch sá»­ thanh toÃ¡n 3 thÃ¡ng gáº§n nháº¥t: PAY_1={customer_data['PAY_1']}, 
      PAY_2={customer_data['PAY_2']}, PAY_3={customer_data['PAY_3']}
    
    Káº¿t quáº£ dá»± bÃ¡o:
    - Dá»± Ä‘oÃ¡n: {'âš ï¸ Rá»¦I RO CAO' if prediction_result['prediction'] == 1 else 'âœ… Rá»¦I RO THáº¤P'}
    - Äá»™ tin cáº­y: {prediction_result['confidence']:.1%}
    - PhÃ¢n cá»¥m: Cluster {prediction_result.get('cluster_id', 'N/A')}
    
    HÃ£y:
    1. Giáº£i thÃ­ch táº¡i sao khÃ¡ch hÃ ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n nhÆ° váº­y
    2. Chá»‰ ra cÃ¡c yáº¿u tá»‘ rá»§i ro chÃ­nh (náº¿u cÃ³)
    3. Äá» xuáº¥t 2-3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ cho bá»™ pháº­n tÃ­n dá»¥ng
    """
    
    response = self.chat_session.send_message(prompt)
    self._save_chat_history(prompt, response.text, "Prediction")
    
    return response.text
```

**Sample Output:**

```
ðŸ“Š PhÃ¢n TÃ­ch Káº¿t Quáº£ Dá»± BÃ¡o

âœ… ÄÃ¡nh GiÃ¡: Rá»¦I RO THáº¤P (Confidence: 82.3%)

ðŸ” LÃ½ Do Dá»± ÄoÃ¡n:
â€¢ Háº¡n má»©c tÃ­n dá»¥ng cao (NT$ 250,000) cho tháº¥y kháº£ nÄƒng tÃ i chÃ­nh tá»‘t
â€¢ Lá»‹ch sá»­ thanh toÃ¡n Ä‘á»u Ä‘áº·n (PAY_1=-1, PAY_2=-1, PAY_3=-1 = tráº£ Ä‘Ãºng háº¡n)
â€¢ Äá»™ tuá»•i 42 - nhÃ³m á»•n Ä‘á»‹nh vá» tÃ i chÃ­nh
â€¢ TrÃ¬nh Ä‘á»™ Ä‘áº¡i há»c - thu nháº­p kháº£ quan

ðŸ“ˆ CÃ¡c Yáº¿u Tá»‘ TÃ­ch Cá»±c:
1. KhÃ´ng cÃ³ láº§n thanh toÃ¡n cháº­m nÃ o trong 3 thÃ¡ng gáº§n nháº¥t
2. Háº¡n má»©c tÃ­n dá»¥ng cao pháº£n Ã¡nh uy tÃ­n tá»‘t vá»›i ngÃ¢n hÃ ng
3. Thuá»™c Cluster 0 (nhÃ³m khÃ¡ch hÃ ng rá»§i ro tháº¥p)

ðŸ’¡ Khuyáº¿n Nghá»‹:
1. âœ… PhÃª duyá»‡t háº¡n má»©c tÃ­n dá»¥ng bá»• sung (náº¿u khÃ¡ch hÃ ng yÃªu cáº§u)
2. ðŸŽ¯ CÃ¢n nháº¯c nÃ¢ng háº¡n má»©c lÃªn 300,000 - 350,000 NT$
3. ðŸ“ž Duy trÃ¬ quan há»‡ tá»‘t, giá»›i thiá»‡u sáº£n pháº©m tÃ­n dá»¥ng Æ°u Ä‘Ã£i
```

## 5.3. Model Comparison

### 5.3.1. Compare Multiple Models

Admin users can compare predictions from different models:

```python
def compare_models(self, customer_data: dict, predictions: dict) -> str:
    """
    Compare predictions from multiple models and explain differences
    """
    prompt = f"""
    So sÃ¡nh káº¿t quáº£ dá»± bÃ¡o tá»« cÃ¡c mÃ´ hÃ¬nh ML khÃ¡c nhau:
    
    ThÃ´ng tin khÃ¡ch hÃ ng: (tÃ³m táº¯t)
    - Háº¡n má»©c: {customer_data['LIMIT_BAL']:,} NT$
    - Thanh toÃ¡n 3 thÃ¡ng: PAY_1={customer_data['PAY_1']}, 
      PAY_2={customer_data['PAY_2']}, PAY_3={customer_data['PAY_3']}
    
    Káº¿t quáº£ tá»« cÃ¡c mÃ´ hÃ¬nh:
    """
    
    for model_name, result in predictions.items():
        prompt += f"\n- {model_name}: {'Rá»¦I RO CAO' if result['prediction'] == 1 else 'Rá»¦I RO THáº¤P'} (Confidence: {result['confidence']:.1%})"
    
    prompt += """
    
    HÃ£y:
    1. Giáº£i thÃ­ch táº¡i sao cÃ¡c mÃ´ hÃ¬nh cho káº¿t quáº£ khÃ¡c nhau (náº¿u cÃ³)
    2. Chá»‰ ra mÃ´ hÃ¬nh nÃ o Ä‘Ã¡ng tin cáº­y nháº¥t vÃ  táº¡i sao
    3. ÄÆ°a ra khuyáº¿n nghá»‹ cuá»‘i cÃ¹ng cho quyáº¿t Ä‘á»‹nh tÃ­n dá»¥ng
    """
    
    response = self.chat_session.send_message(prompt)
    self._save_chat_history(prompt, response.text, "Model")
    
    return response.text
```

**Sample Output:**

```
ðŸ”¬ So SÃ¡nh CÃ¡c MÃ´ HÃ¬nh ML

ðŸ“Š Káº¿t Quáº£:
â€¢ XGBoost: âš ï¸ Rá»¦I RO CAO (68.5%)
â€¢ LightGBM: âš ï¸ Rá»¦I RO CAO (71.2%)
â€¢ LogisticRegression: âœ… Rá»¦I RO THáº¤P (52.3%)

ðŸ” PhÃ¢n TÃ­ch Sá»± KhÃ¡c Biá»‡t:
1. Tree-based models (XGBoost, LightGBM) Ä‘á»“ng thuáº­n vá» rá»§i ro cao
2. Logistic Regression cÃ³ káº¿t quáº£ khÃ¡c biá»‡t do:
   - Chá»‰ há»c má»‘i quan há»‡ tuyáº¿n tÃ­nh
   - KhÃ´ng báº¯t Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡c phá»©c táº¡p giá»¯a cÃ¡c biáº¿n
   - Confidence tháº¥p (52%) = khÃ´ng cháº¯c cháº¯n

ðŸ’¡ MÃ´ HÃ¬nh ÄÃ¡ng Tin Cáº­y Nháº¥t: LightGBM
LÃ½ do:
â€¢ AUC cao nháº¥t (0.7811)
â€¢ Confidence score cao (71.2%)
â€¢ Tá»‘t hÆ¡n trong viá»‡c xá»­ lÃ½ dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng

âœ… Khuyáº¿n Nghá»‹ Cuá»‘i CÃ¹ng:
Dá»±a trÃªn consensus cá»§a 2 mÃ´ hÃ¬nh máº¡nh (XGBoost + LightGBM):
â†’ âš ï¸ Xáº¾P LOáº I: Rá»¦I RO CAO
â†’ ðŸ›¡ï¸ HÃ€NH Äá»˜NG:
  1. YÃªu cáº§u thÃªm tÃ i liá»‡u chá»©ng minh thu nháº­p
  2. Giáº£m háº¡n má»©c tÃ­n dá»¥ng xuá»‘ng cÃ²n 70-80% Ä‘á» xuáº¥t
  3. Theo dÃµi sÃ¡t trong 6 thÃ¡ng Ä‘áº§u
```

## 5.4. Automated Report Generation

### 5.4.1. Generate Executive Summary

```python
def generate_report(self, stats: dict, report_type: str = "monthly") -> str:
    """
    Generate automated reports on system performance and risk analysis
    """
    prompt = f"""
    Táº¡o bÃ¡o cÃ¡o {report_type} vá» há»‡ thá»‘ng dá»± bÃ¡o rá»§i ro tÃ­n dá»¥ng:
    
    Thá»‘ng kÃª:
    - Tá»•ng sá»‘ dá»± bÃ¡o: {stats['total_predictions']}
    - Dá»± Ä‘oÃ¡n rá»§i ro cao: {stats['high_risk_count']} ({stats['high_risk_rate']:.1%})
    - Dá»± Ä‘oÃ¡n rá»§i ro tháº¥p: {stats['low_risk_count']} ({stats['low_risk_rate']:.1%})
    - AUC cá»§a mÃ´ hÃ¬nh active: {stats['active_model_auc']:.4f}
    - Thá»i gian dá»± bÃ¡o trung bÃ¬nh: {stats['avg_prediction_time']:.2f}ms
    
    PhÃ¢n cá»¥m khÃ¡ch hÃ ng:
    - Cluster 0 (Low Risk): {stats['cluster_0_count']} khÃ¡ch hÃ ng
    - Cluster 1 (Medium Risk): {stats['cluster_1_count']} khÃ¡ch hÃ ng
    - Cluster 2 (High Risk): {stats['cluster_2_count']} khÃ¡ch hÃ ng
    - Cluster 3 (Critical Risk): {stats['cluster_3_count']} khÃ¡ch hÃ ng
    
    HÃ£y táº¡o bÃ¡o cÃ¡o gá»“m:
    1. TÃ³m táº¯t executive (3-4 cÃ¢u)
    2. Äiá»ƒm ná»•i báº­t (key highlights)
    3. Xu hÆ°á»›ng rá»§i ro (risk trends)
    4. Khuyáº¿n nghá»‹ hÃ nh Ä‘á»™ng (action items)
    """
    
    response = self.model.generate_content(prompt)
    self._save_chat_history(prompt, response.text, "Report")
    
    return response.text
```

**Sample Output:**

```
ðŸ“Š BÃO CÃO THÃNG 11/2025 - Há»† THá»NG Dá»° BÃO Rá»¦I RO TÃN Dá»¤NG

ðŸŽ¯ TÃ“M Táº®T EXECUTIVE:
Há»‡ thá»‘ng Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng 1,247 dá»± bÃ¡o trong thÃ¡ng 11 vá»›i Ä‘á»™ chÃ­nh xÃ¡c
cao (AUC 0.7604). Tá»· lá»‡ khÃ¡ch hÃ ng rá»§i ro cao giáº£m 3.2% so vá»›i thÃ¡ng trÆ°á»›c,
pháº£n Ã¡nh cháº¥t lÆ°á»£ng danh má»¥c tÃ­n dá»¥ng Ä‘ang cáº£i thiá»‡n. Thá»i gian pháº£n há»“i
trung bÃ¬nh 45ms Ä‘Ã¡p á»©ng tá»‘t yÃªu cáº§u real-time.

âœ¨ ÄIá»‚M Ná»”I Báº¬T:
â€¢ âœ… 78.3% khÃ¡ch hÃ ng Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ Rá»¦I RO THáº¤P
â€¢ âš ï¸ 21.7% khÃ¡ch hÃ ng cáº§n theo dÃµi (rá»§i ro cao/trung bÃ¬nh)
â€¢ ðŸ“ˆ Äá»™ chÃ­nh xÃ¡c tÄƒng 2.1% sau khi chuyá»ƒn sang LightGBM
â€¢ ðŸš€ Há»‡ thá»‘ng xá»­ lÃ½ nhanh hÆ¡n 35% so vá»›i thÃ¡ng 10

ðŸ“Š PHÃ‚N Bá» Rá»¦I RO:
Low Risk (Cluster 0): 654 (52.4%)    â†’ PhÃª duyá»‡t nhanh
Medium Risk (Cluster 1): 323 (25.9%) â†’ Xem xÃ©t ká»¹
High Risk (Cluster 2): 198 (15.9%)   â†’ YÃªu cáº§u bá»• sung tÃ i liá»‡u
Critical Risk (Cluster 3): 72 (5.8%) â†’ Tá»« chá»‘i/háº¡n cháº¿ háº¡n má»©c

ðŸ“ˆ XU HÆ¯á»šNG:
1. Tá»· lá»‡ khÃ¡ch hÃ ng Cluster 0 tÄƒng 5.2% (tÃ­ch cá»±c)
2. Cluster 3 giáº£m 1.8% (giáº£m rá»§i ro nghiÃªm trá»ng)
3. KhÃ¡ch hÃ ng má»›i cÃ³ tá»· lá»‡ rá»§i ro cao hÆ¡n 12% so vá»›i khÃ¡ch hÃ ng cÅ©

ðŸ’¡ KHUYáº¾N NGHá»Š HÃ€NH Äá»˜NG:
1. ðŸŽ¯ NGAY: Review láº¡i 72 khÃ¡ch hÃ ng Cluster 3, cÃ¢n nháº¯c giáº£m háº¡n má»©c
2. ðŸ“ž TRONG TUáº¦N: LiÃªn há»‡ 198 khÃ¡ch hÃ ng Cluster 2 Ä‘á»ƒ cáº­p nháº­t thu nháº­p
3. ðŸ”§ THÃNG Tá»šI: Triá»ƒn khai LightGBM lÃ m mÃ´ hÃ¬nh chÃ­nh (AUC 0.7811)
4. ðŸ“Š DÃ€I Háº N: Thu tháº­p thÃªm dá»¯ liá»‡u vá» thu nháº­p Ä‘á»ƒ cáº£i thiá»‡n mÃ´ hÃ¬nh
```

## 5.5. Chat History Management

### 5.5.1. Store Conversations

All interactions with Gemini AI are logged to the database for audit and continuous improvement:

```python
def _save_chat_history(self, message: str, response: str, context_type: str):
    """Save chat interaction to database"""
    query = """
    INSERT INTO ai_chat_history 
    (user_id, message, response, context_type, created_at)
    VALUES (%s, %s, %s, %s, NOW())
    """
    self.db.execute_query(query, (self.user_id, message, response, context_type))
```

### 5.5.2. Retrieve Conversation History

```python
def get_chat_history(self, limit: int = 50) -> List[dict]:
    """Retrieve recent chat history for current user"""
    query = """
    SELECT message, response, context_type, created_at
    FROM ai_chat_history
    WHERE user_id = %s
    ORDER BY created_at DESC
    LIMIT %s
    """
    results = self.db.fetch_all(query, (self.user_id, limit))
    
    return [
        {
            'message': row[0],
            'response': row[1],
            'context_type': row[2],
            'timestamp': row[3]
        }
        for row in results
    ]
```

---

*Continue to Chapter 6 (Results and Discussion) and Chapter 7 (Conclusion)...*
