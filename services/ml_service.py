"""
ML Service
Service giao ti·∫øp v·ªõi ML models v√† x·ª≠ l√Ω d·ª± b√°o
"""
import sys
from pathlib import Path
from typing import Dict, Optional

# Add ml package to path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from ml.predictor import ModelPredictor
from ml.preprocess import preprocess_input
from models.prediction_result import PredictionResult


class MLService:
    """
    Service qu·∫£n l√Ω ML models v√† d·ª± b√°o
    """
    
    def __init__(self, model_path: Optional[str] = None, model_name: str = 'XGBoost'):
        """
        Kh·ªüi t·∫°o MLService
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n t·ªõi file model .pkl
            model_name: T√™n model (XGBoost/LightGBM/LogisticRegression)
        """
        import traceback
        print(f"üî•üî•üî• MLService.__init__ CALLED with model_name={model_name} üî•üî•üî•")
        print(f"üî• Traceback:")
        for line in traceback.format_stack()[:-1]:
            if 'ui/' in line or 'PredictionTab' in line or 'MainWindow' in line or 'comparison' in line.lower():
                print(f"   {line.strip()}")
        
        self.model_name = model_name
        
        # Default model path n·∫øu kh√¥ng cung c·∫•p
        if model_path is None:
            models_dir = project_root / 'outputs' / 'models'
            if model_name == 'XGBoost':
                model_path = str(models_dir / 'xgb_model.pkl')
            elif model_name == 'LightGBM':
                model_path = str(models_dir / 'lgbm_model.pkl')
            elif model_name == 'LogisticRegression':
                model_path = str(models_dir / 'lr_cal_model.pkl')
            else:
                model_path = str(models_dir / 'xgb_model.pkl')
        
        self.model_path = model_path
        self.predictor = ModelPredictor(self.model_path)
        
        # Load model
        self.predictor.load_model()
    
    def predict_default_risk(self, input_dict: Dict) -> PredictionResult:
        """
        D·ª± b√°o r·ªßi ro v·ª° n·ª£
        
        Args:
            input_dict: Dict ch·ª©a 41 tr∆∞·ªùng features (12 th√°ng l·ªãch s·ª≠)
        
        Returns:
            Instance PredictionResult
        """
        try:
            # Preprocess input
            processed_input = preprocess_input(input_dict)
            
            # Predict
            label, probability = self.predictor.predict(processed_input)
            
            # T·∫°o PredictionResult
            result = PredictionResult(
                label=int(label),
                probability=float(probability),
                model_name=self.model_name,
                raw_outputs={'input': input_dict}
            )
            
            print(f"‚úì D·ª± b√°o: {result}")
            return result
            
        except Exception as e:
            print(f"‚úó L·ªói khi d·ª± b√°o: {e}")
            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh n·∫øu l·ªói
            return PredictionResult(
                label=0,
                probability=0.0,
                model_name=self.model_name,
                raw_outputs={'error': str(e)}
            )
    
    def get_model_info(self) -> Dict:
        """
        L·∫•y th√¥ng tin v·ªÅ model hi·ªán t·∫°i
        
        Returns:
            Dict ch·ª©a th√¥ng tin model
        """
        return {
            'model_name': self.model_name,
            'model_path': self.model_path,
            'is_loaded': self.predictor.model is not None
        }
    
    def reload_model(self, new_model_path: Optional[str] = None):
        """
        Reload model t·ª´ file m·ªõi
        
        Args:
            new_model_path: ƒê∆∞·ªùng d·∫´n model m·ªõi (optional)
        """
        if new_model_path:
            self.model_path = new_model_path
        
        self.predictor = ModelPredictor(self.model_path)
        self.predictor.load_model()
        print(f"‚úì ƒê√£ reload model: {self.model_path}")
