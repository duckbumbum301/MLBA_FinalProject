"""
Gemini AI Service
Service tÃ­ch há»£p Google Gemini cho AI Assistant
"""
import json
import decimal
import time
from typing import Optional, Dict, Any
from datetime import datetime

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except (ImportError, TypeError) as e:
    GEMINI_AVAILABLE = False
    if isinstance(e, TypeError):
        print("âš  google-generativeai khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i Python 3.14. HÃ£y dÃ¹ng Python 3.11-3.12")
    else:
        print("âš  google-generativeai not installed. Install with: pip install google-generativeai")

from config.gemini_config import GeminiConfig
from database.connector import DatabaseConnector


class GeminiService:
    """
    Service quáº£n lÃ½ tÆ°Æ¡ng tÃ¡c vá»›i Gemini AI
    """
    
    def __init__(self, db_connector: DatabaseConnector, user_id: int):
        """
        Khá»Ÿi táº¡o Gemini Service
        
        Args:
            db_connector: Database connector
            user_id: ID cá»§a user Ä‘ang sá»­ dá»¥ng
        """
        self.db = db_connector
        self.user_id = user_id
        self.model = None
        self.chat_session = None
        
        # Initialize if API key is configured
        if GEMINI_AVAILABLE and GeminiConfig.is_configured():
            try:
                genai.configure(api_key=GeminiConfig.API_KEY)
                
                self.model = genai.GenerativeModel(
                    model_name=GeminiConfig.MODEL_NAME,
                    generation_config={
                        "temperature": GeminiConfig.TEMPERATURE,
                        "top_p": GeminiConfig.TOP_P,
                        "top_k": GeminiConfig.TOP_K,
                        "max_output_tokens": GeminiConfig.MAX_OUTPUT_TOKENS,
                    },
                    safety_settings=GeminiConfig.SAFETY_SETTINGS,
                    system_instruction=GeminiConfig.SYSTEM_INSTRUCTION
                )
                
                self.chat_session = self.model.start_chat(history=[])
                print("âœ“ Gemini AI initialized successfully")
                
            except Exception as e:
                print(f"âœ— Failed to initialize Gemini: {e}")
                self.model = None
        else:
            if not GEMINI_AVAILABLE:
                print("âœ— Gemini not available: package not installed")
            elif not GeminiConfig.is_configured():
                print("âœ— Gemini not configured: Please set API_KEY in config/gemini_config.py")
    
    def is_available(self) -> bool:
        """Kiá»ƒm tra Gemini cÃ³ sáºµn sÃ ng khÃ´ng"""
        return self.model is not None
    
    def send_message(
        self, 
        message: str, 
        context: Optional[Dict[str, Any]] = None,
        context_type: str = "General"
    ) -> str:
        """
        Gá»­i message tá»›i Gemini
        
        Args:
            message: CÃ¢u há»i/message tá»« user
            context: Context data (customer data, prediction results, etc.)
            context_type: Loáº¡i context ('Prediction', 'Model Comparison', 'General')
        
        Returns:
            Response tá»« Gemini
        """
        if not self.is_available():
            return "âŒ Gemini AI chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh. Vui lÃ²ng thÃªm API key vÃ o config/gemini_config.py"
        
        try:
            # Prepare full prompt with context
            def _to_json_safe(obj):
                if obj is None:
                    return None
                if isinstance(obj, (str, int, float, bool)):
                    return obj
                if isinstance(obj, decimal.Decimal):
                    try:
                        return float(obj)
                    except Exception:
                        return float(str(obj))
                if isinstance(obj, datetime):
                    return obj.isoformat()
                if isinstance(obj, bytes):
                    try:
                        return obj.decode('utf-8', errors='ignore')
                    except Exception:
                        return str(obj)
                if isinstance(obj, (list, tuple, set)):
                    return [ _to_json_safe(x) for x in list(obj) ]
                if isinstance(obj, dict):
                    return { str(k): _to_json_safe(v) for k, v in obj.items() }
                try:
                    return json.loads(json.dumps(obj))
                except Exception:
                    return str(obj)

            if context:
                context_safe = _to_json_safe(context)
                context_str = json.dumps(context_safe, indent=2, ensure_ascii=False)
                full_prompt = f"""
Context Data:
```json
{context_str}
```

User Question: {message}

HÃ£y phÃ¢n tÃ­ch vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context data á»Ÿ trÃªn.
"""
            else:
                full_prompt = message
            
            # Send to Gemini
            start_time = time.time()
            response = self.chat_session.send_message(full_prompt)
            response_time_ms = int((time.time() - start_time) * 1000)
            
            try:
                response_text = getattr(response, 'text', None)
                if not response_text:
                    # Try generate_content as a fallback
                    try:
                        alt = self.model.generate_content(full_prompt)
                        response_text = getattr(alt, 'text', None)
                    except Exception:
                        response_text = None
                if not response_text:
                    # Build safety-aware message
                    reason = None
                    try:
                        d = response.to_dict()
                        reason = str(d.get('candidates',[{}])[0].get('finish_reason'))
                    except Exception:
                        pass
                    response_text = f"âš  KhÃ´ng thá»ƒ Ä‘á»c pháº£n há»“i tá»« Gemini. finish_reason={reason or 'unknown'}. Vui lÃ²ng thá»­ láº¡i vá»›i cÃ¢u há»i rÃµ rÃ ng hÆ¡n."
            except Exception:
                response_text = "âš  KhÃ´ng thá»ƒ Ä‘á»c pháº£n há»“i tá»« Gemini."
            
            # Save to database
            self._save_chat_history(
                context_type=context_type,
                context_data=context_safe if context else None,
                user_message=message,
                ai_response=response_text,
                response_time_ms=response_time_ms
            )
            
            return response_text
        
        except Exception as e:
            error_msg = f"âŒ Lá»—i khi gá»i Gemini API: {str(e)}"
            print(error_msg)
            return error_msg
    
    def explain_prediction(
        self, 
        customer_data: Dict[str, Any], 
        prediction_result: Dict[str, Any]
    ) -> str:
        """
        Giáº£i thÃ­ch káº¿t quáº£ dá»± bÃ¡o cho khÃ¡ch hÃ ng
        
        Args:
            customer_data: Dá»¯ liá»‡u khÃ¡ch hÃ ng (41 features)
            prediction_result: Káº¿t quáº£ dá»± bÃ¡o (probability, label, model_name)
        
        Returns:
            Giáº£i thÃ­ch tá»« Gemini
        """
        context = {
            "type": "Prediction Explanation",
            "customer": customer_data,
            "prediction": prediction_result
        }
        
        prompt = f"""
PhÃ¢n tÃ­ch káº¿t quáº£ dá»± bÃ¡o rá»§i ro tÃ­n dá»¥ng cho khÃ¡ch hÃ ng nÃ y:

**Káº¿t quáº£ dá»± bÃ¡o:**
- Model: {prediction_result.get('model_name', 'XGBoost')}
- XÃ¡c suáº¥t vá»¡ ná»£: {prediction_result.get('probability', 0)*100:.1f}%
- ÄÃ¡nh giÃ¡: {prediction_result.get('risk_label', 'Unknown')}

**YÃªu cáº§u:**
1. Giáº£i thÃ­ch táº¡i sao khÃ¡ch hÃ ng nÃ y cÃ³ má»©c rá»§i ro nhÆ° váº­y
2. PhÃ¢n tÃ­ch 3-5 yáº¿u tá»‘ quan trá»ng nháº¥t
3. So sÃ¡nh vá»›i khÃ¡ch hÃ ng trung bÃ¬nh
4. ÄÆ°a ra 3 khuyáº¿n nghá»‹ cá»¥ thá»ƒ

Tráº£ lá»i ngáº¯n gá»n, dÃ¹ng bullet points vÃ  emoji.
"""
        
        return self.send_message(prompt, context, "Prediction")
    
    def compare_models(
        self, 
        customer_data: Dict[str, Any],
        predictions: Dict[str, Any]
    ) -> str:
        """
        So sÃ¡nh káº¿t quáº£ tá»« nhiá»u models
        
        Args:
            customer_data: Dá»¯ liá»‡u khÃ¡ch hÃ ng
            predictions: Dict {model_name: prediction_result}
        
        Returns:
            PhÃ¢n tÃ­ch so sÃ¡nh tá»« Gemini
        """
        context = {
            "type": "Model Comparison",
            "customer": customer_data,
            "predictions": predictions
        }
        
        prompt = """
So sÃ¡nh káº¿t quáº£ dá»± Ä‘oÃ¡n tá»« cÃ¡c mÃ´ hÃ¬nh Machine Learning khÃ¡c nhau:

**YÃªu cáº§u:**
1. So sÃ¡nh xÃ¡c suáº¥t tá»« tá»«ng model
2. Giáº£i thÃ­ch táº¡i sao cÃ³ sá»± khÃ¡c biá»‡t
3. Model nÃ o Ä‘Ã¡ng tin cáº­y nháº¥t cho trÆ°á»ng há»£p nÃ y?
4. CÃ³ Ä‘iá»ƒm báº¥t thÆ°á»ng nÃ o khÃ´ng?

Tráº£ lá»i ngáº¯n gá»n vá»›i bullet points.
"""
        
        return self.send_message(prompt, context, "Model Comparison")
    
    def generate_report(
        self, 
        stats: Dict[str, Any],
        report_type: str = "monthly"
    ) -> str:
        """
        Táº¡o bÃ¡o cÃ¡o tá»± Ä‘á»™ng
        
        Args:
            stats: Dá»¯ liá»‡u thá»‘ng kÃª
            report_type: Loáº¡i bÃ¡o cÃ¡o ('monthly', 'weekly', 'custom')
        
        Returns:
            BÃ¡o cÃ¡o Markdown tá»« Gemini
        """
        context = {
            "type": "Report Generation",
            "report_type": report_type,
            "statistics": stats
        }
        
        prompt = f"""
Táº¡o bÃ¡o cÃ¡o {report_type} cho há»‡ thá»‘ng Credit Risk Scoring:

**Format bÃ¡o cÃ¡o (Markdown):**
1. ## ðŸ“Š TÃ³m Táº¯t Tá»•ng Quan (Executive Summary)
2. ## ðŸ“ˆ Thá»‘ng KÃª Dá»± BÃ¡o (Prediction Statistics)
3. ## ðŸŽ¯ PhÃ¢n TÃ­ch Rá»§i Ro (Risk Analysis)
4. ## ðŸ¤– Hiá»‡u Suáº¥t MÃ´ HÃ¬nh (Model Performance)
5. ## ðŸ’¡ Khuyáº¿n Nghá»‹ (Recommendations)
6. ## ðŸ“‰ Xu HÆ°á»›ng (Trends)

DÃ¹ng tables, bullet points, vÃ  emoji. Ngáº¯n gá»n, táº­p trung vÃ o insights quan trá»ng.
"""
        
        return self.send_message(prompt, context, "Report Generation")
    
    def ask_general(self, question: str) -> str:
        """
        Há»i cÃ¢u há»i chung vá» credit risk
        
        Args:
            question: CÃ¢u há»i
        
        Returns:
            CÃ¢u tráº£ lá»i tá»« Gemini
        """
        return self.send_message(question, None, "General")
    
    def _save_chat_history(
        self,
        context_type: str,
        context_data: Optional[Dict],
        user_message: str,
        ai_response: str,
        response_time_ms: int
    ):
        """LÆ°u lá»‹ch sá»­ chat vÃ o database"""
        try:
            query = """
                INSERT INTO ai_chat_history 
                (user_id, context_type, context_data, user_message, ai_response, response_time_ms)
                VALUES (%s, %s, %s, %s, %s, %s)
            """
            
            def _to_json_safe_db(obj):
                # Reuse same logic as above but avoid circular reference
                if obj is None:
                    return None
                if isinstance(obj, (str, int, float, bool)):
                    return obj
                if isinstance(obj, decimal.Decimal):
                    try:
                        return float(obj)
                    except Exception:
                        return float(str(obj))
                if isinstance(obj, datetime):
                    return obj.isoformat()
                if isinstance(obj, bytes):
                    try:
                        return obj.decode('utf-8', errors='ignore')
                    except Exception:
                        return str(obj)
                if isinstance(obj, (list, tuple, set)):
                    return [ _to_json_safe_db(x) for x in list(obj) ]
                if isinstance(obj, dict):
                    return { str(k): _to_json_safe_db(v) for k, v in obj.items() }
                return str(obj)

            context_json = json.dumps(_to_json_safe_db(context_data)) if context_data else None
            
            self.db.execute_query(
                query,
                (self.user_id, context_type, context_json, user_message, ai_response, response_time_ms)
            )
        except Exception as e:
            print(f"âš  Could not save chat history: {e}")
    
    def get_chat_history(self, limit: int = 50) -> list:
        """
        Láº¥y lá»‹ch sá»­ chat cá»§a user
        
        Args:
            limit: Sá»‘ lÆ°á»£ng messages tá»‘i Ä‘a
        
        Returns:
            List of chat messages
        """
        query = """
            SELECT context_type, user_message, ai_response, created_at
            FROM ai_chat_history
            WHERE user_id = %s
            ORDER BY created_at DESC
            LIMIT %s
        """
        
        results = self.db.fetch_all(query, (self.user_id, limit))
        
        history = []
        for row in results:
            history.append({
                'context_type': row[0],
                'user_message': row[1],
                'ai_response': row[2],
                'created_at': row[3]
            })
        
        return list(reversed(history))  # Oldest first
    
    def clear_chat_history(self):
        """XÃ³a lá»‹ch sá»­ chat vÃ  reset session"""
        if self.chat_session and self.model:
            self.chat_session = self.model.start_chat(history=[])
            print("âœ“ Chat session reset")
